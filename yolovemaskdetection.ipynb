{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below code is for face mask detection in the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "net = cv2.dnn.readNet('yolov3_training_last.weights', 'yolov3_testing.cfg')\n",
    "\n",
    "classes = []\n",
    "with open(\"classes.txt\", \"r\") as f:\n",
    "    classes = f.read().splitlines()\n",
    "\n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0, 255, size=(100, 3))\n",
    "\n",
    "#reading the image\n",
    "img = cv2.imread('00.jpg')      \n",
    "\n",
    "height, width, channels = img.shape\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "layerOutputs = net.forward(output_layers_names)\n",
    "\n",
    "boxes = []\n",
    "confidences = []\n",
    "class_ids = []\n",
    "\n",
    "for output in layerOutputs:\n",
    "    for detection in output:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.2:\n",
    "            center_x = int(detection[0]*width)\n",
    "            center_y = int(detection[1]*height)\n",
    "            w = int(detection[2]*width)\n",
    "            h = int(detection[3]*height)\n",
    "\n",
    "            x = int(center_x - w/2)\n",
    "            y = int(center_y - h/2)\n",
    "\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append((float(confidence)))\n",
    "            class_ids.append(class_id)\n",
    "\n",
    "#using Non-maximum suppression and getting the object identified \n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.2, 0.4)\n",
    "\n",
    "#using cv2 to draw reactangles around the objects identified\n",
    "if len(indexes)>0:\n",
    "    for i in indexes.flatten():\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = str(classes[class_ids[i]])\n",
    "        confidence = str(round(confidences[i],2))\n",
    "        #color = (0, 255, 0) if label == \"with_mask\" else (0, 0, 255)\n",
    "        #color = colors[i]\n",
    "        color = (0, 255, 0) if label == \"with_mask\" else (0, 0, 255)\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "        #cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255,255,255), 2)\n",
    "        \n",
    "cv2.imshow('Image',img)\n",
    "#cv2.imwrite('new1.png',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use below code, when using the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "net = cv2.dnn.readNet('yolov3_training_last.weights', 'yolov3_testing.cfg')\n",
    "\n",
    "classes = []\n",
    "with open(\"classes.txt\", \"r\") as f:\n",
    "    classes = f.read().splitlines()\n",
    "\n",
    "cap = cv2.VideoCapture(\"2.mp4\") #when using web cam use 0 as the parameters\n",
    "                                #for saved videos use the path of teh videos as parameter e.g \"path/ayaz/video.mp4\"\n",
    "                            \n",
    "\n",
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0, 255, size=(100, 3))\n",
    "\n",
    "#choosing the saved video frame sizes \n",
    "frame_width = int(cap.get(3)) \n",
    "frame_height = int(cap.get(4)) \n",
    "   \n",
    "size = (frame_width, frame_height) \n",
    "\n",
    "#used for saving teh video file and th3 format is specified\n",
    "\n",
    "result = cv2.VideoWriter('videofilename.avi',  \n",
    "                         cv2.VideoWriter_fourcc(*'MJPG'), \n",
    "                         10, size) \n",
    "\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    height, width, channels = img.shape\n",
    "    \n",
    "    #preprocessing the frames\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "    layerOutputs = net.forward(output_layers_names)\n",
    "\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.2:\n",
    "                center_x = int(detection[0]*width)\n",
    "                center_y = int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h = int(detection[3]*height)\n",
    "\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h/2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append((float(confidence)))\n",
    "                class_ids.append(class_id)\n",
    "    #using Non-maximum suppression and getting the object identified \n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.2, 0.4)\n",
    "    \n",
    "    #using cv2 to draw reactangles around the objects identified\n",
    "    if len(indexes)>0:\n",
    "        for i in indexes.flatten():\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = str(round(confidences[i],2))\n",
    "            #color = colors[i]\n",
    "            color = (0, 255, 0) if label == \"with_mask\" else (0, 0, 255)\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "            #cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255,255,255), 2)\n",
    "    \n",
    "    result.write(img)\n",
    "    #uncomment the below line to show the video processing in real time \n",
    "    #cv2.imshow('Image', img)\n",
    "    key = cv2.waitKey(1)\n",
    "    #press esc key to exit the cv2.video showing window\n",
    "    if key==27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "result.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
